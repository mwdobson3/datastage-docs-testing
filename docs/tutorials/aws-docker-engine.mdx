---
sidebar_position: 2
title: AWS EC2 (Docker)
description: Deploy DataStage Remote Engine on Amazon EC2 with Docker
---

# Deploy DataStage Remote Engine on AWS EC2 with Docker

Learn how to deploy a DataStage Remote Engine on Amazon EC2 using Docker to run data integration workloads close to your data sources while maintaining centralized control through IBM Cloud Pak for Data.

## Why Deploy with Docker?

Docker provides a lightweight, portable containerization solution for DataStage engines with:

- **Simplicity**: Single-server deployment with minimal infrastructure
- **Quick Setup**: Faster deployment compared to Kubernetes
- **Cost-Effective**: Ideal for development, testing, or smaller workloads
- **Portability**: Consistent environment across different platforms
- **Easy Management**: Simple start/stop/restart operations

## Architecture Overview

<div style={{textAlign: 'center', margin: '2rem 0'}}>
  <img 
    src="/datastage-docs-testing/img/datastage-anywhere-architecture.png" 
    alt="DataStage as a Service Anywhere Architecture" 
    style={{maxWidth: '100%', height: 'auto', borderRadius: '8px', boxShadow: '0 4px 6px rgba(0,0,0,0.1)'}}
  />
</div>

### Key Components

**Design-time on IBM Cloud**
- Manage projects and user access
- Design DataStage jobs using the web-based canvas
- Import existing DataStage assets
- Administrative tools and monitoring

**DataStage Runtime Execution**
- Initiates API calls to remote engine
- Pulls job metadata and orchestrates execution
- Firewall allows only outbound connections for security

**Remote Engine (On EC2 Instance)**
- **PX Runtime (Conductor)**: Orchestrates parallel job execution
- **PX Compute**: Parallel processing containers for data transformation
- **Persistent Volume**: Stores engine configuration and temporary data
- Deployed as Docker containers on a single EC2 instance

### Benefits

✅ **Retain full data privacy** - Data never leaves your environment  
✅ **Reduce egress/ingress fines** - Minimize unnecessary data movement  
✅ **Improved performance** - Process data where it resides  
✅ **Retain data sovereignty** - Comply with data locality regulations

## When to Use Docker vs. Kubernetes

**Choose Docker when:**
- Running development or test environments
- Processing smaller data volumes
- Need quick setup with minimal infrastructure
- Single-server deployment is sufficient
- Cost optimization is a priority

**Choose Kubernetes when:**
- Running production workloads at scale
- Need high availability and auto-scaling
- Processing large data volumes
- Require multi-tenancy and resource isolation
- Enterprise-grade orchestration is required

## What You'll Learn

This tutorial walks you through:

1. **Prerequisites and Setup** - Required tools and access
2. **Launch EC2 Instance** - Create and configure AWS instance
3. **Install Docker** - Set up Docker with secondary storage
4. **Generate Encryption Keys** - Create security credentials
5. **Deploy Remote Engine** - Install DataStage with Docker
6. **Verify and Configure** - Test deployment and connect to Cloud Pak

## Prerequisites

Before starting, ensure you have:

- AWS account with EC2 permissions
- IBM Cloud Pak for Data instance (SaaS or on-premises)
- Basic knowledge of Linux and Docker
- SSH client for remote access

## Time Estimate

⏱️ **Total Time**: 30-45 minutes

- EC2 setup: 10-15 minutes
- Docker installation: 5-10 minutes  
- Engine deployment: 10-15 minutes
- Verification: 5-10 minutes

---

<div style={{textAlign: 'center', margin: '3rem 0'}}>
  <a 
    href="/datastage-docs-testing/docs/tutorials/aws-docker-engine/prerequisites" 
    className="button button--primary button--lg"
  >
    Start Tutorial →
  </a>
</div>